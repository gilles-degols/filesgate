filesgate {

  akka {
    loggers = [ "akka.event.slf4j.Slf4jLogger" ]
    loglevel = "DEBUG"

    log-dead-letters = 0
    log-dead-letters-during-shutdown = true

    actor {
      provider = "akka.remote.RemoteActorRefProvider"
    }

    remote {
      enabled-transports = ["akka.remote.netty.tcp"]
      netty.tcp {
        hostname = "127.0.0.1"
        port = 2200
      }
    }
  }


  internal {
    engine-actor {
      // To reduce concurrency issues, you should not put a value smaller than 5-10 s for each of the following attributes
      check-pipeline-manager-state-ms = 5000
      check-pipeline-instance-state-ms = 5000
      check-pipeline-step-state-ms = 5000
    }
  }

  storage {
    # Default storage for downloaded files. This can be overrided on a file-basis and changed whenever
    # you want.
    content {
      # If we never want to save file information, we can deactivate the storing of files. This
      # can be useful if you want to compute some information from the file, and not store any result
      # through FilesGate.
      activate = true
      mongo {
        uri = "localhost:27017"
      }
    }

    # Default storage for the internal working of FilesGate. This should not changed once installed, otherwise
    # migration scripts are needed
    metadata {
      mongo {
        hosts = "localhost:27017"
        database = "filesgate"
        collection = "filesStatus"
      }
    }
  }

  # Various settings having an impact on the performance of the system. Tune it according
  # to your needs
  performance {
    # Threads used for every part of the system (download, pre-post processing, ...)
    threads = 2
  }

  # List of the different pipelines we want to have
  pipelines {
    # Name of the pipeline as key
    example {

      # Not mandatory, this is a configuration to automatically fetch the data from well known data sources (kafka, MongoDB, ...)
      # TODO: Implement it
      default-steps {
        source {
          "Core:package:default-source.kafka" {
            bootstrap-servers = ["localhost:27017"]
            topic = []
            partitions = 2 // We should fetch it dynamically if possible...
          }

          json-mapping {
            url = "url"
          }
        }
      }

      # List of expected steps we need to have before allowing the system to start. This is necessary has we need to have
      # every pipeline step to be able to process a file correctly. The number of actor instances for each of those step-ids
      # is handled by the developer when he extends the EngineLeader and ask instances with those specific names.
      # The actors could be implemented in other JVMs so we need to provide the full path. If the full path is not provided,
      # we automatically assume that we are using the actor from the current jvm.
      # As we can use actors from other jvm, each worker must accept messages from multiple PipelineManager / PipelineInstance.
      # If we want to limit the number of instances used by the current pipeline (instance), we can provide a limitation on the number
      # of involved actors. if the value does not exist or is set to -1, any number can be used based on the one available in the cluster.
      steps = [
        # Where should we fetch the data? This step is the only one mandatory. The "sink" is not even mandatory.
        {type: "source", name:"Core:Package:default.source", max-instances:1},

        # To detect if the current pipeline should be used with a given message
        {type: "matcher", name:"Core:Package:default.matcher", max-instances:1},

        {type: "predownload",name: "Core:Package:default.preDownload", max-instances: 1},
        {type: "download",name: "Core:Package:default.download", max-instances: 1},
        {type: "prestorage", name: "Core:Package:default.preStorage", max-instances: 1},
        {type: "storage", name: "Core:Package:default.storage", max-instances: 1},
        {type: "poststorage",name: "Core:Package:default.postStorage", max-instances: 1}
      ]

      # The configuration for the number of pipeline instance to use for this pipeline (more specifically the load balancer).
      # A PipelineInstance is only in charge of one Pipeline id.
      # This is default configuration, in the future, we will allow the EngineLeader to override it.
      pipeline-instance {
        # Number of PipelineInstances.
        quantity = 2
      }
    }
  }
}
